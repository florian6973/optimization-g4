{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('Flo': conda)",
   "metadata": {
    "interpreter": {
     "hash": "85c75fd14e5076fbcb18764378155d0efe7f43fc87250a2b11ec2cf5a4ffd7c5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Notes\n",
    "\n",
    "Diminuer le pas, va marcher mais trop long\n",
    "gradient amorti, gradient à pas optimal\n",
    "\n",
    "c1 = 10^-4, c2 = 0.9\n",
    "\n",
    "Style de rendu ?\n",
    "\n",
    "Questions\n",
    "- q6 manque une composante vecteur c, alpha non négligeable ?\n",
    "- q7 max coût ou profit ?\n",
    "- q8 norme non différentiable en 0 ?\n",
    "- calculer gradient à la main ou autograd ? besoin pour scipy ? problème décompose vecteur z...\n",
    "- deux algorithmes à trouver... : newton avec pénalisation (mais pas dans le cours ?) et gradient proximal ?\n",
    "- vérifier avec scipy (ou à utiliser ?), quel choix de méthode ? calcul gradient des fonctions & des coûts ?\n",
    "- scipy à la fin : production négative : rajouter des contraintes\n",
    "- résultat pas entier : moitié de croissant ? où arrondir ?\n",
    "- résultat différent : mauvaise valeur de alpha... ? à quoi s'attendre ?\n",
    "- grande variabilité selon la valeur de alpha ? bizarre première méthode... ou problème scipy slsqp sans gradient spécifié (important) ?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "source": [
    "## 1. Etude du problème d'optimisation\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Le coût (2) correspond au profit de la boulangerie :\n",
    "\n",
    "- $c^T r$ est le coût d'achat des matières premières\n",
    "- $v^T q$ est le montant rapporté par la vente d'une quantité de produits $q$ (tout ce qui a été produit)\n",
    "- $v^T d$ est le montant rapporté par la vente d'une quantité de produits $d$ (tout ce qui a été demandé)\n",
    "\n",
    "Ainsi, le terme $\\min\\{q,d\\}$ correspond à la quantité minimum entre ce qui a été produit ou demandé. En effet, le facteur limitant des gains dépend si la demande est supérieure à la production ou si la production est supérieure à la demande (dans le cas d'économies d'échelle par exemple, cela peut être rentable).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2\n",
    "\n",
    "Ce terme avec un $\\min$ n'est pas un opérateur linéaire, il n'est donc peut-être pas différentiable et ne permet pas d'appliquer les méthodes du cours les plus efficaces."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 3\n",
    "\n",
    "Cette formule fait penser à la statistique de Maxwell-Boltzmann.\n",
    "\n",
    "Soit $i \\in [|1, p|]$.\n",
    "\n",
    "Cas 1 : $q_i > d_i$. Montrons que $h_i \\approx d_i$.\n",
    "\n",
    "$\\exp(-\\alpha q_i) << \\exp(-\\alpha d_i)$ et $q_i \\exp(-\\alpha q_i)$ est toujours petit devant $d_i \\exp(-\\alpha d_i)$ car $\\alpha >> 1$, ce qui permet de simplifier et d'obtenir le résultat.\n",
    "\n",
    "Cas 2 : $q_i < d_i$. On procède de manière similaire par symétrie\n",
    "\n",
    "On a donc maintenant une fonction convexe différentiable ce qui permet de se placer dans un cadre où l'on dispose plus de résultats."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 4\n",
    "\n",
    "On suppose que $d$ est fixé. On pose :\n",
    "\n",
    "- $z = (q, r)$ (de taille $n=p + m$)\n",
    "- $f(z) = f(q, r) = c^T r - v^T h(q, d)$, à valeurs dans $\\mathbb{R}$\n",
    "- $c(z) = c(q, r) = A q - r$ ($m$ contraintes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Etude et résolution numérique\n",
    "\n",
    "### Question 5\n",
    "\n",
    "Puisque la fonction $f$ est deux-fois différentiable, on peut utiliser la méthode la plus efficace pour l'optimisation différentiable, c'est-à-dire la méthode de Newton. Toutefois, il faut prendre en compte les contraintes inégalités. On peut donc penser à une optimisation avec pénalités.\n",
    "\n",
    "Une autre approche serait les algorithmes d'optimisiation différentiable sous contraintes, comme celui Uzawa ou d'Arrow-Hurwicz (les contraintes sont linéaires)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 6\n",
    "\n",
    "Il est surprenant que $1$ ne soit pas négligeable devant $\\alpha$..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def q6():\n",
    "    alpha = 0.1\n",
    "    c = 1e-3*np.array([30.,1.,4.,1., 1.])\n",
    "    v = np.array([0.9, 1.5, 1.1])\n",
    "    d = np.array([400., 67., 33.])\n",
    "    A = np.array([[3.5,2.,1.],[250.,80., 25.],[0., 8., 3.],[0., 40., 10.], [0., 8.5, 0.]])\n",
    "    n = len(c)+len(d)\n",
    "    return n, alpha, c, v, d, A\n",
    "\n",
    "n, alpha, c, v, d, A = q6()\n",
    "x0 = np.zeros(n)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.         2.09757685 4.4227762 ]\n-8.747419084891563\n[0.03  0.001 0.004 0.001 0.001]\n"
     ]
    }
   ],
   "source": [
    "def fun_h(q, d, alpha=alpha):\n",
    "    return (q*np.exp(-alpha*q)+d*np.exp(-alpha*d))/(np.exp(-alpha*q)+np.exp(-alpha*d))\n",
    "\n",
    "print(fun_h(np.array([1.,2.,3.]), d))\n",
    "\n",
    "def fun_f(z, d=d, A=A, c=c, v=v, alpha=alpha):\n",
    "    q = z[:len(d)]\n",
    "    r = z[len(d):]\n",
    "    return c.T @ r - v.T @ fun_h(q, d, alpha)\n",
    "\n",
    "ztest = np.array([1.,2.,3.,4.,5.,6.,7.,8.])\n",
    "print(fun_f(ztest))\n",
    "\n",
    "def fun_c(z, A=A):\n",
    "    q = z[:len(d)]\n",
    "    r = z[len(d):]\n",
    "    return A @ q - r\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -341.7322637556364\n",
      "            Iterations: 73\n",
      "            Function evaluations: 673\n",
      "            Gradient evaluations: 73\n",
      "[   402.13044074     74.7795287      43.07691189   1600.09251189\n",
      " 107591.89527865    727.46696531   3421.95026712    635.62599399]\n",
      "<ipython-input-130-a1a4604c4267>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return (q*np.exp(-alpha*q)+d*np.exp(-alpha*d))/(np.exp(-alpha*q)+np.exp(-alpha*d))\n",
      "<ipython-input-130-a1a4604c4267>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (q*np.exp(-alpha*q)+d*np.exp(-alpha*d))/(np.exp(-alpha*q)+np.exp(-alpha*d))\n"
     ]
    }
   ],
   "source": [
    "ineq_cons = { 'type' : 'ineq' , 'fun' : lambda x: - fun_c(x)}\n",
    "res = optimize . minimize(fun_f, x0, method= 'SLSQP' ,\n",
    "constraints= [ineq_cons], options={ 'disp' : True, 'maxiter': 10000})\n",
    "\n",
    "print(res.x)"
   ]
  },
  {
   "source": [
    "Légère surproduction : très étonnant, économie d'échelle ? pas tout à fait comme intuition : plutôt moins ou = à la demande mais pas plus...\n",
    "\n",
    "\n",
    "Comparer aussi la valeur du profit en lui-même... ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a. Problème d'optimisation.\n",
    "\n",
    "On calcule l'espérance de l'opposé du profit : $E(z)=\\pi_1 f_1(z)+\\pi_2 f_2(z)+\\pi_3 f_3(z)$ où $f_i(z)= c^T r - v^T h(q, d^i)$\n",
    "\n",
    "On minimise donc cette quantité $E(z)$ avec les mêmes contraintes.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q7():\n",
    "    d1 = np.array([400., 67., 33.])\n",
    "    d2 = np.array([500., 80., 53.])\n",
    "    d3 = np.array([300., 60., 43.])\n",
    "    p1 = 0.5\n",
    "    p2 = 0.3\n",
    "    p3 = 0.2\n",
    "    return d1, p1, d2, p2, d3, p3\n",
    "\n",
    "ps = q7()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_E(z, ps=ps):\n",
    "    d1, p1, d2, p2, d3, p3 = ps\n",
    "    return p1*fun_f(z, d1)+p2*fun_f(z, d2)+p3*fun_f(z, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n            Current function value: -332.85639212736544\n            Iterations: 72\n            Function evaluations: 665\n            Gradient evaluations: 72\n[   406.7080966      79.35835244     55.24061306   1637.43565605\n 109406.70767265    800.58865869   3726.74022815    674.54599573]\n"
     ]
    }
   ],
   "source": [
    "ineq_cons = { 'type' : 'ineq' , 'fun' : lambda x: - fun_c(x)}\n",
    "res = optimize . minimize(fun_E, x0, method= 'SLSQP' ,\n",
    "constraints= [ineq_cons], options={ 'disp' : True, 'maxiter': 10000})\n",
    "\n",
    "print(res.x)"
   ]
  },
  {
   "source": [
    "Produit un peu plus pour couvrir la variabilité si plus de demande car proba plus de demande plus importante que demande plus faible ?\n",
    "\n",
    "Comparer aussi la valeur du profit en lui-même..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 8\n",
    "\n",
    "a. On suppose que $r$ et $d$ sont fixés. On a toujours le terme de revenus $v^T h(q,d)$. Le premier terme correspond à $(q-d)^T(q-d)$. $q-d$ est la différence entre ce qui est produit et ce qui est demandé. Cela correspond donc au coût induit par le gaspillage si $q>d$, ou le coût de la non-satisfaction de la demande si $d>q$d. On cherche donc bien à minimiser ce coût..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "b. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n            Current function value: -332.85639212736544\n            Iterations: 72\n            Function evaluations: 665\n            Gradient evaluations: 72\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -407.55865453752693\n            Iterations: 7\n            Function evaluations: 30\n            Gradient evaluations: 7\n[300.2195123   60.36145378  43.26755944]\n"
     ]
    }
   ],
   "source": [
    "ineq_cons = { 'type' : 'ineq' , 'fun' : lambda x: - fun_c(x)}\n",
    "res = optimize . minimize(fun_E, x0, method= 'SLSQP' ,\n",
    "constraints= [ineq_cons], options={ 'disp' : True, 'maxiter': 10000})\n",
    "\n",
    "y = res.x\n",
    "#print(y)\n",
    "r = y[len(d):]\n",
    "#print(r)\n",
    "\n",
    "def fun_g(q, d=ps[4], v=v):\n",
    "    return (q-d).T @ (q-d) - v.T @ fun_h(q, d) # attention norme au carré\n",
    "\n",
    "def fun_cb(q, r=r, d=ps[4]):\n",
    "    return fun_c(np.hstack((q, r)))\n",
    "\n",
    "y0 = np.zeros(len(d))\n",
    "#print(y0)\n",
    "\n",
    "ineq_cons = { 'type' : 'ineq' , 'fun' : lambda x: - fun_cb(x)}\n",
    "res = optimize . minimize(fun_g, y0, method= 'SLSQP' ,\n",
    "constraints= [ineq_cons], options={ 'disp' : True, 'maxiter': 10000})\n",
    "print(res.x)\n"
   ]
  },
  {
   "source": [
    "Moins de gaspillage ? Adapté Très proche de la demande $d^3$\n",
    "\n",
    "\n",
    "Comparer aussi la valeur du profit en lui-même..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Etude du problème non-régularisé\n",
    "\n",
    "### Question 9\n",
    "\n",
    "Méthode de gradient proximale (optimisation non-différentiable ?) (cf Traitement du Signal ?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2. 3.]\n-7.0360000000000005\n"
     ]
    }
   ],
   "source": [
    "def fun_hb(q, d, alpha=alpha):\n",
    "    return np.minimum(q,d)\n",
    "\n",
    "print(fun_hb(np.array([1.,2.,3.]), d))\n",
    "\n",
    "def fun_fb(z, d=d, A=A, c=c, v=v, alpha=alpha):\n",
    "    q = z[:len(d)]\n",
    "    r = z[len(d):]\n",
    "    return c.T @ r - v.T @ fun_hb(q, d, alpha)\n",
    "\n",
    "def fun_cb(z, A=A):\n",
    "    q = z[:len(d)]\n",
    "    r = z[len(d):]\n",
    "    return np.hstack((A @ q - r,-q))\n",
    "\n",
    "ztest = np.array([1.,2.,3.,4.,5.,6.,7.,8.])\n",
    "print(fun_fb(ztest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n            Current function value: -222.3135315308291\n            Iterations: 59\n            Function evaluations: 615\n            Gradient evaluations: 59\n[   399.98099087     80.88927743     33.0000028    2175.50014173\n 107291.38998093  12510.8926088   43039.11616086   8830.27942088]\n"
     ]
    }
   ],
   "source": [
    "ineq_cons = { 'type' : 'ineq' , 'fun' : lambda x: - fun_cb(x)}\n",
    "res = optimize . minimize(fun_fb, x0, method= 'SLSQP' ,\n",
    "constraints= [ineq_cons], options={ 'disp' : True, 'maxiter': 10000})\n",
    "print(res.x)\n",
    "\n",
    "# résultat fantasiste : méthode de scipy pas adaptée au problème ? profit positif car opposé du résultat...\n",
    "# SLSQP pourtant OK pour non linéaire ? problème gradient ?\n",
    "# problème alpha ?\n",
    "\n",
    "# pas possible production négative ?? rajout d'une contrainte : fun_cb"
   ]
  },
  {
   "source": [
    "Résultat assez différents (quantifier ?) : normal ou non ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}